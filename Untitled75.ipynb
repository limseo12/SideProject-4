{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOOpbU6NOn9kdSiTiz4PnGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limseo12/SideProject-4/blob/main/Untitled75.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리를 설치합니다."
      ],
      "metadata": {
        "id": "9qVeFOgpIUgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6Zyr26pH7TB"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tacotron2"
      ],
      "metadata": {
        "id": "Mhzq9uWCIxCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "RFoO974CI0Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리 설명\\\n",
        "import os \\\n",
        "운영체제에 사용하기 위해 import합니다.\\\n",
        "import torch \\\n",
        "import torch.nn \\\n",
        "import torch.utils.data \\\n",
        "import torch.optim \\\n",
        "import torch.nn.functional \\\n",
        "import torchaudio \\\n",
        "ifrom torch.utils.data import Dataset, DataLoader\\\n",
        "import numpy\\\n",
        "import unicodedata\\\n",
        "import re\\\n",
        "import time\\\n",
        "from torch.autograd import Variable\\\n",
        "from math import sqrt\\\n"
      ],
      "metadata": {
        "id": "bqStrNGaJX9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter 설정 및 device 확인\n",
        "class HParams():\n",
        "    def __init__(self):\n",
        "        self.n_mel_channels = 80    #125Hz에서 7.6kHz에 걸쳐있는 80 channel mel filterbank를 사용하여 STFT magnitude를 mel scale로 변환하고 이어서 log dynamic range compression을 합니다.\n",
        "        # Model Parameters\n",
        "        self.symbols_embedding_dim=512    #텍스트에서 임베딩을 합니다 룩업테이블을 통해 임베딩합니다. 입력 정수에 대해 밀집 벡터(dense vector)로 맵핑하고 이 밀집 벡터는 인공 신경망의 학습 과정에서 가중치가 학습되는 것과 같은 방식입니다.\n",
        "        #Encoder parameters\n",
        "        self.encoder_kernel_size=5    #레이어별 인코더 컨볼루션 필터 크기입니다\n",
        "        self.encoder_n_convolutions=3   #앞에서 설정했던 크기가 5인 컨볼루션 필터의 갯수 입니다\n",
        "        self.encoder_embedding_dim=512    #각 방향(전방 및 후방)에 대한 lstm의 수 이며 뒤쪽 부분에 나옵니다.\n",
        "\n",
        "        # Decoder parameters\n",
        "        self.n_frames_per_step=1  # 타코트론의 경우 멜을 출력으로 낼 때 하나 이상의 멜 스펙트롤을 뱉는다,타코트론2에서는 계산속도는 빠르나 성능이 떨어질 수 있기에 1로고정\n",
        "        self.decoder_rnn_dim=1024   \n",
        "        self.prenet_dim=256   # 레이어 수 및 prenet 단위 수\n",
        "        self.max_decoder_steps=1000   #추론(inference) 중 최대 디코더 단계 (무한 루프 에서 멈추기 위해) 설정\n",
        "        self.gate_threshold=0.5\n",
        "        self.p_attention_dropout=0.1    #attention의 dropout 비율\n",
        "        self.p_decoder_dropout=0.1    #decoder의 dropout 비율\n",
        "\n",
        "        # Attention parameters\n",
        "        self.attention_rnn_dim=1024\n",
        "        self.attention_dim=128    #Attention 의 차원\n",
        "\n",
        "        # Location Layer parameters\n",
        "        self.attention_location_n_filters=32\n",
        "        self.attention_location_kernel_size=31\n",
        "\n",
        "        # Mel-post processing network parameters\n",
        "        self.postnet_embedding_dim=512    #포스트넷 임베딩값\n",
        "        self.postnet_kernel_size=5    #포스트넷의 레이어별 컨볼루션 필터 크기\n",
        "        self.postnet_n_convolutions=5   #컨볼루션 필터 갯수\n",
        "\n",
        "        # Optimization Hyperparameters\n",
        "        self.use_saved_learning_rate=False    #출력 범위에 맞게 정규화 가중치를 재조정할지 여부(reg_weight가 높고 모델을 바이어스할 때 사용됨)\n",
        "        self.learning_rate=1e-3   #초기 학습 속도. 기본값은 1e-4 이다.\n",
        "        self.weight_decay=1e-6    #가중치 감쇠 계수. 기본값이 1e-6 이다.\n",
        "        self.grad_clip_thresh=1.0   #그라데이션 클리핑 임계값. 기본값은 5 이다.\n",
        "        self.batch_size=4   \n",
        "        self.mask_padding=True  # set model's padded outputs to padded values\n",
        "    \n",
        "    \n",
        "hparams = HParams()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('GPU를 사용할 준비가 되었습니다.')\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print('CPU 모드입니다. GPU 설정으로 변경해주세요.')"
      ],
      "metadata": {
        "id": "X_9Ug_2dKIQN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}